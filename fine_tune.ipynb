{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import json\n",
    "import matplotlib\n",
    "import timm\n",
    "import torch\n",
    "from fastai.vision.all import (\n",
    "    F1Score,\n",
    "    accuracy,\n",
    "    Precision,\n",
    "    Recall,\n",
    "    DataLoaders,\n",
    "    Learner,\n",
    "    SaveModelCallback,\n",
    "    valley,\n",
    "    slide,\n",
    "    ClassificationInterpretation)\n",
    "from data import get_dls_from_images, get_dls_from_dataset\n",
    "import io\n",
    "import os\n",
    "\n",
    "from datasets import Dataset, concatenate_datasets, load_dataset\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fastai.vision.all import (\n",
    "    Path,\n",
    "    DataBlock,\n",
    "    ImageBlock,\n",
    "    CategoryBlock,\n",
    "    Resize,\n",
    "    aug_transforms,\n",
    "    Normalize,\n",
    "    get_image_files,\n",
    "    parent_label,\n",
    "    imagenet_stats,\n",
    ")\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastcore.foundation import L, range_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efficientnet_b0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "model_name = config[\"model\"][\"timm_model_name\"]\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "def get_dls_from_images():\n",
    "    #path = \"C:/BitBucketRepo/datascienceprojects/ChartExt/Images/\" #Path(config[\"data\"][\"image_dir\"])\n",
    "    #img_size = config[\"data\"][\"transformations\"][\"img_size\"]\n",
    "\n",
    "    data = pd.read_excel(\"C:/BitBucketRepo/datascienceprojects/ChartExt/res.xlsx\")\n",
    "    data['label'] = data['label'].apply(str)\n",
    "    labels = data['label']\n",
    "    X_train, X_temp = train_test_split(data, test_size=0.2, stratify=labels, random_state = 42)\n",
    "    label_test_val = X_temp['label']\n",
    "    X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state = 42)\n",
    "\n",
    "    image_size = 128\n",
    "    image_channel = 3\n",
    "    bat_size = 32\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range = 15,\n",
    "                                    horizontal_flip = True,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    shear_range = 0.1,\n",
    "                                    fill_mode = 'reflect',\n",
    "                                    width_shift_range = 0.1,\n",
    "                                    height_shift_range = 0.1)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(X_train,\n",
    "                                                    directory = 'C:/BitBucketRepo/datascienceprojects/ChartExt/Images/',\n",
    "                                                    x_col= 'filename',\n",
    "                                                    y_col= 'label',\n",
    "                                                    batch_size = bat_size,\n",
    "                                                    target_size = (image_size,image_size)\n",
    "                                                   )\n",
    "    val_generator = test_datagen.flow_from_dataframe(X_val, \n",
    "                                                    directory = 'C:/BitBucketRepo/datascienceprojects/ChartExt/Images/',\n",
    "                                                    x_col= 'filename',\n",
    "                                                    y_col= 'label',\n",
    "                                                    batch_size = bat_size,\n",
    "                                                    target_size = (image_size,image_size),\n",
    "                                                    shuffle=False\n",
    "                                                    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(X_test, \n",
    "                                                    directory = 'C:/BitBucketRepo/datascienceprojects/ChartExt/Images/',\n",
    "                                                    x_col= 'filename',\n",
    "                                                    y_col= 'label',\n",
    "                                                    batch_size = bat_size,\n",
    "                                                    target_size = (image_size,image_size),\n",
    "                                                    shuffle=False\n",
    "                                                    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "#train_dl, val_dl, test_dl = get_dls_from_images(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "image_channel = 3\n",
    "bat_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from efficientnet.keras import EfficientNetB3\n",
    "from keras.models import Sequential\n",
    "class ChartRecognizer:\n",
    "    def __init__(self):\n",
    "        # Read model args from config.json\n",
    "        with open(\"config.json\", \"r\") as config_file:\n",
    "            self.config = json.load(config_file)\n",
    "\n",
    "        model_name = self.config[\"model\"][\"timm_model_name\"]\n",
    "\n",
    "        # Change format of timm_models\n",
    "        '''timm_models = [\n",
    "            model.split(\".\")[0] for model in timm.list_models(pretrained=True)\n",
    "        ]\n",
    "        if model_name not in timm_models:\n",
    "            raise ValueError(\n",
    "                f\"Model {model_name} not found in timm.list_models(pretrained=True)\"\n",
    "            )\n",
    "\n",
    "        self.model = timm.create_model(model_name, pretrained=True, num_classes=2)'''\n",
    "        efficient_net = EfficientNetB3(\n",
    "        weights='imagenet',\n",
    "        input_shape=(128,128,3),\n",
    "        include_top=False,\n",
    "        pooling='max')\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(efficient_net)\n",
    "        self.model.add(Dense(units = 120, activation='relu'))\n",
    "        self.model.add(Dense(units = 120, activation = 'relu'))\n",
    "        self.model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "        # For converting config.json to function\n",
    "        self.metrics_dict = {\n",
    "            \"f1_score\": F1Score(),\n",
    "            \"precision\": Precision(),\n",
    "            \"recall\": Recall(),\n",
    "            \"accuracy\": accuracy,\n",
    "        }\n",
    "\n",
    "    def train(self):\n",
    "        train_generator, val_generator, test_generator = get_dls_from_images()\n",
    "\n",
    "        \n",
    "\n",
    "        # Find an appropriate learning rate\n",
    "        # learn.lr_find()\n",
    "        #suggested_lr = learn.lr_find(suggest_funcs=(valley, slide))[0]\n",
    "        \n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience=2,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr = 0.00001,\n",
    "                                            verbose = 1)\n",
    "        early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)\n",
    "\n",
    "        self.model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "        self.model.fit(train_generator,\n",
    "                    validation_data = val_generator, \n",
    "                    callbacks=[early_stoping,learning_rate_reduction],\n",
    "                    epochs = 15,\n",
    "                    # steps_per_epoch = len(train_generator),\n",
    "                    # validation_steps = len(val_generaotor),\n",
    "                   )\n",
    "    def predictt(self):\n",
    "        train_generator, val_generator, test_generator = get_dls_from_images()\n",
    "        self.model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116 validated image filenames belonging to 2 classes.\n",
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4/4 [==============================] - 25s 2s/step - loss: 1.8054 - accuracy: 0.5000 - val_loss: 0.7577 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7948 - accuracy: 0.5000 - val_loss: 0.7225 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7629 - accuracy: 0.5000\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7629 - accuracy: 0.5000 - val_loss: 0.7150 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7237 - accuracy: 0.5000 - val_loss: 0.7172 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 5/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7089 - accuracy: 0.5000\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7089 - accuracy: 0.5000 - val_loss: 0.7103 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 6/15\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7047 - accuracy: 0.5000 - val_loss: 0.7084 - val_accuracy: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 7/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7025 - accuracy: 0.5000 - val_loss: 0.7071 - val_accuracy: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 8/15\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7014 - accuracy: 0.5000 - val_loss: 0.7070 - val_accuracy: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 9/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7000 - accuracy: 0.5000\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7000 - accuracy: 0.5000 - val_loss: 0.7066 - val_accuracy: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 10/15\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6991 - accuracy: 0.5000 - val_loss: 0.7063 - val_accuracy: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 11/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.5000\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6971 - accuracy: 0.5000 - val_loss: 0.7061 - val_accuracy: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 12/15\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6987 - accuracy: 0.5000 - val_loss: 0.7053 - val_accuracy: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 13/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.5000\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6991 - accuracy: 0.5000 - val_loss: 0.7044 - val_accuracy: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 14/15\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6993 - accuracy: 0.5000 - val_loss: 0.7038 - val_accuracy: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 15/15\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.5000\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6971 - accuracy: 0.5000 - val_loss: 0.7031 - val_accuracy: 0.5000 - lr: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = ChartRecognizer()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116 validated image filenames belonging to 2 classes.\n",
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "Found 116 validated image filenames belonging to 2 classes.\n",
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from timm.data import resolve_data_config, create_transform\n",
    "train_generator, val_generator, test_generator = get_dls_from_images()\n",
    "model.predictt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
